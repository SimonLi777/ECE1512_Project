{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Distillation Learning"
      ],
      "metadata": {
        "id": "3ey80VXUC_8R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7SIb8fIf3ZA"
      },
      "source": [
        "##Loading Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAN3cXkraj5v",
        "outputId": "ba5f08b7-a563-4c71-ab1d-284fb6dd1ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Anp0hJWeGPW",
        "outputId": "1ceee10b-ee16-43d9-ab81-a9ab57fc69ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/ECE1512 Assignment 2/networks.py'\n",
            "'/content/drive/MyDrive/ECE1512 Assignment 2/utils.py'\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/ECE1512\\ Assignment\\ 2/*.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kQQpKMzodW5z"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ECE1512 Assignment 2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvSAHJyLlN3z",
        "outputId": "b1e1f2ab-51e7-4eda-ba01-1b625227eec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.1.2.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.7.1.2-py3-none-any.whl size=13213 sha256=ea1f0f33ccc494ffafbbf7e5eddd757e5ce6f28a26785a000e71dbdda16dc791\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/90/07/20e8c3221349a85d63b319593e1bcbb6e0c995d2e2bcc5d775\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ptflops\n",
        "import networks\n",
        "from utils import get_dataset, get_network, evaluate_synset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from ptflops import get_model_complexity_info\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#from torchvision.utils import save_image, make_grid\n",
        "#from ptflops import get_model_complexity_info\n",
        "from utils import get_dataset, get_network, TensorDataset, get_time\n",
        "import matplotlib.pyplot as plt\n",
        "builder = tfds.builder('mnist')\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 256\n",
        "#MODEL = 'ConvNet'\n",
        "#IMAGE_PER_CLASS = 10\n",
        "#EVAL_MODE = 'SS'\n",
        "#LR_IMG = 1\n",
        "#LR_NET = 0.01\n",
        "NUMBER_CLASSES = 10\n",
        "#ITERATIONS = 10\n",
        "#NUMBER_INITIALIZATIONS = 100\n",
        "#NUMBER_STEP_OPT = 50\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b1g6jtwoA-1"
      },
      "source": [
        "#Create dataset for MHIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xGCicCldoFiy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CqNAifN8oEeQ"
      },
      "outputs": [],
      "source": [
        "###############\n",
        "#https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/6f5f4fbfa307e6755c583593b9623cfb/custom_dataset_transforms_loader.ipynb#scrollTo=agFaBk4wlbB2\n",
        "###############\n",
        "class MHIST(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.mhist_labels = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mhist_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.mhist_labels.iloc[idx, 0])\n",
        "        images = io.imread(img_name)\n",
        "        #if self.mhist_labels.iloc[idx, 1] == 'HP':\n",
        "        labels = self.mhist_labels.iloc[idx, 1]\n",
        "        #labels = np.array([labels])\n",
        "        #labels = labels.astype('float').reshape(-1, 2)\n",
        "        #sample = {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "        if self.transform:\n",
        "            images = self.transform(images)\n",
        "\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "73XMxs8KpQ-0"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 2\n",
        "mhist_dataset = MHIST(csv_file='/content/drive/MyDrive/images/annotations_v2.csv',root_dir='/content/drive/MyDrive/images/', transform=transforms.ToTensor())\n",
        "train_set, test_set = torch.utils.data.random_split(mhist_dataset, [2522, 630])\n",
        "trainloader_mhist = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader_mhist = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9_97KLpinaR"
      },
      "source": [
        "# 2.a Train the selected model with the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WsvHb9AMkx-L"
      },
      "outputs": [],
      "source": [
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(\"MNIST\", \"/content/drive/MyDrive/MNIST\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "A8SSgrCcfl5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d5a933-7246-49a4-8156-db6783e27d67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /content/drive/MyDrive/MNIST\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.1307], std=[0.3081])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dst_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "d55q2bg1lSp8"
      },
      "outputs": [],
      "source": [
        "model = get_network(\"ConvNet\", channel, num_classes, im_size).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WywK-9NBvlNf"
      },
      "outputs": [],
      "source": [
        "mnist_train, mnist_test = dst_train, dst_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "889gBXkyOHUQ"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "lossFn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0I39dzPaeTQY"
      },
      "outputs": [],
      "source": [
        "trainloader = torch.utils.data.DataLoader(dst_train, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HM_Q-VPhp_5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b51432-1367-44f1-a7f4-c53207bdb20b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x79098febd870>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "trainloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lGpZBC-O9iks"
      },
      "outputs": [],
      "source": [
        "def compute_num_correct(model, testloader):\n",
        "  model.eval()\n",
        "  valCorrect = 0\n",
        "  #val_loss = 0\n",
        "  for (images, labels) in testloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "    pred = model(images)\n",
        "    #val_loss += lossFn(pred, labels)\n",
        "    valCorrect += (pred.argmax(1) == labels).type(torch.float).sum().item()\n",
        "  return valCorrect\n",
        "\n",
        "def train_and_evaluate(model, trainloader, testloader):\n",
        "  test_acc_list = []\n",
        "  print('%s Training begins'%get_time())\n",
        "  for epoch in range(0, NUM_EPOCHS+1):\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    #Training\n",
        "    model.train()\n",
        "    train_loss = 0.\n",
        "\n",
        "    for (images, labels) in trainloader:\n",
        "      #images, labels = data\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "      opt.zero_grad()\n",
        "      pred = model(images)\n",
        "\n",
        "      loss = lossFn(pred, labels)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      #train_loss += loss.item()\n",
        "    #Evaluation\n",
        "    test_acc = compute_num_correct(model, testloader)/len(testloader.dataset)\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(test_acc * 100))\n",
        "    test_acc_list.append(test_acc)\n",
        "###################\n",
        "#caiquanshi\n",
        "#https://github.com/caiquanshi/ECE1512_2022F_ProjectRepo_CaiquanShi_JunchengMo/blob/main/Project%20B/task1/projectb_task1.ipynb\n",
        "###################\n",
        "  print('%s Training ends'%get_time())\n",
        "  macs, params = get_model_complexity_info(model, (channel, im_size[0], im_size[1]), as_strings=True,\n",
        "                                           print_per_layer_stat=False, verbose=True)\n",
        "  print(\"Flops: {}\".format(macs))\n",
        "\n",
        "  return test_acc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJcaTByL91ts"
      },
      "outputs": [],
      "source": [
        "mnist_acc = train_and_evaluate(model, trainloader, testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i30N_mEbuZvp"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "#\n",
        "##################\n",
        "class Swish(nn.Module): # Swish(x) = x∗σ(x)\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input * torch.sigmoid(input)\n",
        "\n",
        "class ConvNet7(nn.Module):\n",
        "    def __init__(self, channel, num_classes, net_width, net_depth, net_act, net_norm, net_pooling, im_size = (224,224)):\n",
        "        super(ConvNet7, self).__init__()\n",
        "\n",
        "        self.features, shape_feat = self._make_layers(channel, net_width, net_depth, net_norm, net_act, net_pooling, im_size)\n",
        "        num_feat = shape_feat[0]*shape_feat[1]*shape_feat[2]\n",
        "        self.classifier = nn.Linear(num_feat, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def embed(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out\n",
        "\n",
        "    def _get_activation(self, net_act):\n",
        "        if net_act == 'sigmoid':\n",
        "            return nn.Sigmoid()\n",
        "        elif net_act == 'relu':\n",
        "            return nn.ReLU(inplace=True)\n",
        "        elif net_act == 'leakyrelu':\n",
        "            return nn.LeakyReLU(negative_slope=0.01)\n",
        "        elif net_act == 'swish':\n",
        "            return Swish()\n",
        "        else:\n",
        "            exit('unknown activation function: %s'%net_act)\n",
        "\n",
        "    def _get_pooling(self, net_pooling):\n",
        "        if net_pooling == 'maxpooling':\n",
        "            return nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        elif net_pooling == 'avgpooling':\n",
        "            return nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        elif net_pooling == 'none':\n",
        "            return None\n",
        "        else:\n",
        "            exit('unknown net_pooling: %s'%net_pooling)\n",
        "\n",
        "    def _get_normlayer(self, net_norm, shape_feat):\n",
        "        # shape_feat = (c*h*w)\n",
        "        if net_norm == 'batchnorm':\n",
        "            return nn.BatchNorm2d(shape_feat[0], affine=True)\n",
        "        elif net_norm == 'layernorm':\n",
        "            return nn.LayerNorm(shape_feat, elementwise_affine=True)\n",
        "        elif net_norm == 'instancenorm':\n",
        "            return nn.GroupNorm(shape_feat[0], shape_feat[0], affine=True)\n",
        "        elif net_norm == 'groupnorm':\n",
        "            return nn.GroupNorm(4, shape_feat[0], affine=True)\n",
        "        elif net_norm == 'none':\n",
        "            return None\n",
        "        else:\n",
        "            exit('unknown net_norm: %s'%net_norm)\n",
        "\n",
        "    def _make_layers(self, channel, net_width, net_depth, net_norm, net_act, net_pooling, im_size):\n",
        "        layers = []\n",
        "        in_channels = channel\n",
        "        if im_size[0] == 28:\n",
        "            im_size = (32, 32)\n",
        "        shape_feat = [in_channels, im_size[0], im_size[1]]\n",
        "        for d in range(net_depth):\n",
        "            layers += [nn.Conv2d(in_channels, net_width, kernel_size=3, padding=3 if channel == 1 and d == 0 else 1)]\n",
        "            shape_feat[0] = net_width\n",
        "            if net_norm != 'none':\n",
        "                layers += [self._get_normlayer(net_norm, shape_feat)]\n",
        "            layers += [self._get_activation(net_act)]\n",
        "            in_channels = net_width\n",
        "            if net_pooling != 'none':\n",
        "                layers += [self._get_pooling(net_pooling)]\n",
        "                shape_feat[1] //= 2\n",
        "                shape_feat[2] //= 2\n",
        "\n",
        "        return nn.Sequential(*layers), shape_feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F9jqik3TwUUK"
      },
      "outputs": [],
      "source": [
        "def get_default_convnet_setting():\n",
        "    net_width, net_depth, net_act, net_norm, net_pooling = 128, 3, 'relu', 'instancenorm', 'avgpooling'\n",
        "    return net_width, net_depth, net_act, net_norm, net_pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Kpu9-21Qv0ge"
      },
      "outputs": [],
      "source": [
        "net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()\n",
        "model_convnet7 = ConvNet7(channel=3, num_classes=2, net_width=net_width, net_depth=7, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=(224,224)).to(DEVICE)\n",
        "opt = torch.optim.SGD(model_convnet7.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "lossFn = nn.CrossEntropyLoss()\n",
        "channel = 3\n",
        "im_size = (224,224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJTeIUNPtvwv"
      },
      "outputs": [],
      "source": [
        "mhist_acc = train_and_evaluate(model_convnet7, trainloader_mhist, testloader_mhist)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_convnet7\n",
        "channel = 3\n",
        "im_size = (224, 224)\n",
        "macs, params = get_model_complexity_info(model, (channel, im_size[0], im_size[1]), as_strings=True,\n",
        "                                           print_per_layer_stat=False, verbose=True)\n",
        "print(\"Flops: {}\".format(macs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLkUCDyFz7Eg",
        "outputId": "110b231b-090a-4bfa-829f-2c95720285df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module ConvNet7 is treated as a zero-op.\n",
            "Flops: 2.7 GMac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cba9OLoziORR"
      },
      "source": [
        "#2.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dWK60MAsmLNX"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image, make_grid\n",
        "IMAGE_PER_CLASS = 10\n",
        "EVAL_MODE = 'SS'\n",
        "TRAIN_NET_EPOCH = 20\n",
        "BATCH_SIZE = 256\n",
        "LR_IMG = 1\n",
        "LR_NET = 0.01\n",
        "NUMBER_CLASSES = 10\n",
        "ITERATIONS = 10\n",
        "NUMBER_INITIALIZATIONS = 100\n",
        "NUMBER_STEP_OPT = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "W4xoiMv8s-nH"
      },
      "outputs": [],
      "source": [
        "def evaluate(model,valid_data):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for data in valid_data:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        output = model(inputs)\n",
        "        output = torch.argmax(output, dim=1)\n",
        "        correct += torch.sum(output == labels)\n",
        "        total += BATCH_SIZE\n",
        "    return correct / float(total)\n",
        "\n",
        "def train_and_eval(model, image_syn_eval, syn_lable, dst_test):\n",
        "  dst_train = TensorDataset(image_syn_eval, syn_lable)\n",
        "  trainloader = torch.utils.data.DataLoader(dst_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  validLoader = torch.utils.data.DataLoader(dst_test, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=LR_NET)\n",
        "  cee = nn.CrossEntropyLoss()\n",
        "  valid_accs = []\n",
        "  for epoch in range(TRAIN_NET_EPOCH):\n",
        "    model.train()\n",
        "    train_loss = 0.\n",
        "\n",
        "    for data in trainloader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = cee(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    valid_acc = evaluate(model, validLoader)\n",
        "    valid_accs.append(valid_acc)\n",
        "    print(\"Epoch: {} \\tTraining Cost: {:.6f}\\t \"\n",
        "        \"Valid Acc: {}.\".format(epoch, train_loss, valid_acc))\n",
        "  return valid_accs\n",
        "\n",
        "def train_model(model, image_syn_eval, syn_lable, epochs):\n",
        "  dst_train = TensorDataset(image_syn_eval, syn_lable)\n",
        "  trainloader = torch.utils.data.DataLoader(dst_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=LR_NET)\n",
        "  cee = nn.CrossEntropyLoss().to(DEVICE)\n",
        "  for e in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.\n",
        "\n",
        "    for data in trainloader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = cee(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def match_mse_loss(gw_syn, gw_real):\n",
        "  gw_real_vec = []\n",
        "  gw_syn_vec = []\n",
        "  for ig in range(len(gw_real)):\n",
        "      gw_real_vec.append(gw_real[ig].reshape((-1)))\n",
        "      gw_syn_vec.append(gw_syn[ig].reshape((-1)))\n",
        "  gw_real_vec = torch.cat(gw_real_vec, dim=0)\n",
        "  gw_syn_vec = torch.cat(gw_syn_vec, dim=0)\n",
        "  dis = torch.sum((gw_syn_vec - gw_real_vec) ** 2)\n",
        "  return dis\n",
        "\n",
        "\n",
        "def condensed_images_and_evaluate(dataset_name, model_name, eval_mode_name, randmon_init=False):\n",
        "  channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(dataset_name, DATAPATH)\n",
        "  class_index = {}\n",
        "  data_save = []\n",
        "  for i in range(len(dst_train)):\n",
        "    lable = dst_train[i][1]\n",
        "    if lable in class_index:\n",
        "      class_index[lable].append(i)\n",
        "    else:\n",
        "      class_index[lable] = [i]\n",
        "  images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
        "  images_all = torch.cat(images_all, dim=0).to(DEVICE)\n",
        "  syn_image = []\n",
        "  for c in range(num_classes):\n",
        "    idx_shuffle = np.random.permutation(class_index[c])[:IMAGE_PER_CLASS]\n",
        "    syn_image.append(images_all[idx_shuffle])\n",
        "  syn_image = torch.cat(syn_image, dim=0).to(DEVICE)\n",
        "  syn_image.requires_grad = True\n",
        "  syn_lable = []\n",
        "  for c in range(num_classes):\n",
        "    syn_lable += [c for i in range(IMAGE_PER_CLASS)]\n",
        "  if randmon_init:\n",
        "    syn_image = torch.randn(size=(num_classes*IMAGE_PER_CLASS, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=DEVICE)\n",
        "  syn_lable = torch.tensor(syn_lable,device=DEVICE)\n",
        "  optimizer_img = torch.optim.SGD([syn_image, ], lr=LR_IMG)\n",
        "  criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "  total_loss = 0\n",
        "  print('%s training begins'%get_time())\n",
        "  for exp in range(NUMBER_INITIALIZATIONS):\n",
        "    model = get_network(model_name, channel, num_classes, im_size).to(DEVICE)\n",
        "    model.train()\n",
        "    net_parameters = list(model.parameters())\n",
        "\n",
        "    for it in range(ITERATIONS):\n",
        "      loss = torch.tensor(0.0).to(DEVICE)\n",
        "      for c in range(num_classes):\n",
        "        strat_index = c*IMAGE_PER_CLASS\n",
        "        img_real = images_all[np.random.permutation(class_index[c])[:BATCH_SIZE]]\n",
        "        lab_real = torch.ones((BATCH_SIZE,), device=DEVICE, dtype=torch.long) * c\n",
        "        img_syn = syn_image[strat_index: strat_index + IMAGE_PER_CLASS].reshape((IMAGE_PER_CLASS, channel, im_size[0], im_size[1]))\n",
        "        lab_syn = torch.ones((IMAGE_PER_CLASS,), device=DEVICE, dtype=torch.long) * c\n",
        "        output_real = model(img_real)\n",
        "        loss_real = criterion(output_real, lab_real)\n",
        "        gw_real = torch.autograd.grad(loss_real, net_parameters)\n",
        "        gw_real = list((_.detach().clone() for _ in gw_real))\n",
        "\n",
        "        output_syn = model(img_syn)\n",
        "        loss_syn = criterion(output_syn, lab_syn)\n",
        "        gw_syn = torch.autograd.grad(loss_syn, net_parameters, create_graph=True)\n",
        "        loss += match_mse_loss(gw_syn, gw_real)\n",
        "\n",
        "      total_loss += loss\n",
        "      optimizer_img.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer_img.step()\n",
        "\n",
        "      image_syn_train, label_syn_train = copy.deepcopy(syn_image.detach()), copy.deepcopy(syn_lable.detach())  # avoid any unaware modification\n",
        "      train_model(model, image_syn_train, label_syn_train, NUMBER_STEP_OPT)\n",
        "\n",
        "  random = \"Gaussian noise\" if randmon_init else \"real training images\"\n",
        "  save_name = os.path.join(SAVEPATH, 'vis_%s_%s_%s_%d.png'%(model_name, dataset_name, random, IMAGE_PER_CLASS))\n",
        "  image_syn_vis = copy.deepcopy(syn_image.detach().cpu())\n",
        "  save_image(image_syn_vis, save_name, nrow=IMAGE_PER_CLASS)\n",
        "  make_grid(image_syn_vis, nrow=IMAGE_PER_CLASS)\n",
        "  net_eval = get_network(eval_mode_name, channel, num_classes, im_size).to(DEVICE)\n",
        "  image_syn_eval = copy.deepcopy(syn_image.detach())\n",
        "\n",
        "  print('%s training begins'%get_time())\n",
        "  acc_test = train_and_eval(net_eval, image_syn_eval, syn_lable, dst_test)\n",
        "  print('%s training end'%get_time())\n",
        "  return acc_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MFJyfS__lssW"
      },
      "outputs": [],
      "source": [
        "DATAPATH = \"/content/drive/MyDrive/MNIST\"\n",
        "SAVEPATH = \"/content/drive/MyDrive/MNIST_condense\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list_MNIST = condensed_images_and_evaluate(\"MNIST\", \"ConvNet\", \"ConvNet\")"
      ],
      "metadata": {
        "id": "pefjORv5hU6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OYimRtYE9P9q"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()\n",
        "model_convnet7 = ConvNet7(channel=3, num_classes=2, net_width=net_width, net_depth=7, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=(224,224)).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kX4pzNAX8xBp"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "#https://github.com/caiquanshi/ECE1512_2022F_ProjectRepo_CaiquanShi_JunchengMo/blob/main/Project%20B/task1/projectb_task1.ipynb\n",
        "#################\n",
        "def condensed_images_and_evaluate_MHIST(dataset_name, model_name, eval_mode_name, randmon_init=False):\n",
        "  channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(\"MNIST\", \"/content/drive/MyDrive/MNIST\")\n",
        "  channel = 3\n",
        "  num_classes = 2\n",
        "  dst_train = train_set\n",
        "  dst_test = test_set\n",
        "  im_size = (224,224)\n",
        "\n",
        "  class_index = {}\n",
        "  data_save = []\n",
        "  for i in range(len(dst_train)):\n",
        "    lable = dst_train[i][1]\n",
        "    if lable in class_index:\n",
        "      class_index[lable].append(i)\n",
        "    else:\n",
        "      class_index[lable] = [i]\n",
        "  images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
        "  images_all = torch.cat(images_all, dim=0).to(DEVICE)\n",
        "  syn_image = []\n",
        "  for c in range(num_classes):\n",
        "    idx_shuffle = np.random.permutation(class_index[c])[:IMAGE_PER_CLASS]\n",
        "    syn_image.append(images_all[idx_shuffle])\n",
        "  syn_image = torch.cat(syn_image, dim=0).to(DEVICE)\n",
        "  syn_image.requires_grad = True\n",
        "  syn_lable = []\n",
        "  for c in range(num_classes):\n",
        "    syn_lable += [c for i in range(IMAGE_PER_CLASS)]\n",
        "  if randmon_init:\n",
        "    syn_image = torch.randn(size=(num_classes*IMAGE_PER_CLASS, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=DEVICE)\n",
        "  syn_lable = torch.tensor(syn_lable,device=DEVICE)\n",
        "  optimizer_img = torch.optim.SGD([syn_image, ], lr=LR_IMG)\n",
        "  criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "  total_loss = 0\n",
        "  print('%s training begins'%get_time())\n",
        "  for exp in range(NUMBER_INITIALIZATIONS):\n",
        "    #model = get_network(model_name, channel, num_classes, im_size).to(DEVICE)\n",
        "    model = ConvNet7(channel=3, num_classes=2, net_width=net_width, net_depth=7, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=(224,224)).to(DEVICE)\n",
        "    model.train()\n",
        "    net_parameters = list(model.parameters())\n",
        "\n",
        "    for it in range(ITERATIONS):\n",
        "      loss = torch.tensor(0.0).to(DEVICE)\n",
        "      for c in range(num_classes):\n",
        "        strat_index = c*IMAGE_PER_CLASS\n",
        "        img_real = images_all[np.random.permutation(class_index[c])[:BATCH_SIZE]]\n",
        "        lab_real = torch.ones((BATCH_SIZE,), device=DEVICE, dtype=torch.long) * c\n",
        "        img_syn = syn_image[strat_index: strat_index + IMAGE_PER_CLASS].reshape((IMAGE_PER_CLASS, channel, im_size[0], im_size[1]))\n",
        "        lab_syn = torch.ones((IMAGE_PER_CLASS,), device=DEVICE, dtype=torch.long) * c\n",
        "        output_real = model(img_real)\n",
        "        loss_real = criterion(output_real, lab_real)\n",
        "        gw_real = torch.autograd.grad(loss_real, net_parameters)\n",
        "        gw_real = list((_.detach().clone() for _ in gw_real))\n",
        "\n",
        "        output_syn = model(img_syn)\n",
        "        loss_syn = criterion(output_syn, lab_syn)\n",
        "        gw_syn = torch.autograd.grad(loss_syn, net_parameters, create_graph=True)\n",
        "        loss += match_mse_loss(gw_syn, gw_real)\n",
        "\n",
        "      total_loss += loss\n",
        "      optimizer_img.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer_img.step()\n",
        "\n",
        "      image_syn_train, label_syn_train = copy.deepcopy(syn_image.detach()), copy.deepcopy(syn_lable.detach())  # avoid any unaware modification\n",
        "      train_model(model, image_syn_train, label_syn_train, NUMBER_STEP_OPT)\n",
        "\n",
        "  random = \"Gaussian noise\" if randmon_init else \"real training images\"\n",
        "  save_name = os.path.join(SAVEPATH, 'vis_%s_%s_%s_%d.png'%(model_name, dataset_name, random, IMAGE_PER_CLASS))\n",
        "  image_syn_vis = copy.deepcopy(syn_image.detach().cpu())\n",
        "  save_image(image_syn_vis, save_name, nrow=IMAGE_PER_CLASS)\n",
        "  make_grid(image_syn_vis, nrow=IMAGE_PER_CLASS)\n",
        "  #net_eval = get_network(eval_mode_name, channel, num_classes, im_size).to(DEVICE)\n",
        "  net_eval = ConvNet7(channel=3, num_classes=2, net_width=net_width, net_depth=7, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=(224,224)).to(DEVICE)\n",
        "  image_syn_eval = copy.deepcopy(syn_image.detach())\n",
        "\n",
        "  print('%s training begins'%get_time())\n",
        "  acc_test = train_and_eval(net_eval, image_syn_eval, syn_lable, dst_test)\n",
        "  print('%s training end'%get_time())\n",
        "  return acc_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6EsFjOE-zp-",
        "outputId": "a273dac2-42e1-453d-c780-edb22871a97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-12-06 03:53:12] training begins\n",
            "[2023-12-06 04:34:08] training begins\n",
            "Epoch: 0 \tTraining Cost: 8.991707\t Valid Acc: 0.3222222328186035.\n",
            "Epoch: 1 \tTraining Cost: 6.269272\t Valid Acc: 0.561904788017273.\n",
            "Epoch: 2 \tTraining Cost: 4.919905\t Valid Acc: 0.3365079462528229.\n",
            "Epoch: 3 \tTraining Cost: 3.656777\t Valid Acc: 0.47460317611694336.\n",
            "Epoch: 4 \tTraining Cost: 2.551062\t Valid Acc: 0.47460317611694336.\n",
            "Epoch: 5 \tTraining Cost: 1.760011\t Valid Acc: 0.5444444417953491.\n",
            "Epoch: 6 \tTraining Cost: 1.343847\t Valid Acc: 0.45079365372657776.\n",
            "Epoch: 7 \tTraining Cost: 0.994573\t Valid Acc: 0.4650793671607971.\n",
            "Epoch: 8 \tTraining Cost: 0.767305\t Valid Acc: 0.45079365372657776.\n",
            "Epoch: 9 \tTraining Cost: 0.614199\t Valid Acc: 0.4365079402923584.\n",
            "Epoch: 10 \tTraining Cost: 0.514436\t Valid Acc: 0.4396825432777405.\n",
            "Epoch: 11 \tTraining Cost: 0.439834\t Valid Acc: 0.44285714626312256.\n",
            "Epoch: 12 \tTraining Cost: 0.385893\t Valid Acc: 0.43809524178504944.\n",
            "Epoch: 13 \tTraining Cost: 0.338105\t Valid Acc: 0.43809524178504944.\n",
            "Epoch: 14 \tTraining Cost: 0.301008\t Valid Acc: 0.44285714626312256.\n",
            "Epoch: 15 \tTraining Cost: 0.273662\t Valid Acc: 0.4412698447704315.\n",
            "Epoch: 16 \tTraining Cost: 0.247643\t Valid Acc: 0.4396825432777405.\n",
            "Epoch: 17 \tTraining Cost: 0.227086\t Valid Acc: 0.4412698447704315.\n",
            "Epoch: 18 \tTraining Cost: 0.209889\t Valid Acc: 0.43809524178504944.\n",
            "Epoch: 19 \tTraining Cost: 0.194800\t Valid Acc: 0.44285714626312256.\n",
            "[2023-12-06 04:39:47] training end\n"
          ]
        }
      ],
      "source": [
        "acc_list_MHIST = condensed_images_and_evaluate_MHIST(\"MHIST\", \"ConvNet7\", \"ConvNet7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCpDrDagdk7W"
      },
      "source": [
        "#2.d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StPZoOXFdpaS",
        "outputId": "e86f05b1-a8c7-4e80-fed4-8d5a61b8ed96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-06 14:26:22] training begins\n",
            "[2023-12-06 15:59:52] training begins\n",
            "Epoch: 0 \tTraining Cost: 168.761447\t Valid Acc: 0.10159999877214432.\n",
            "Epoch: 1 \tTraining Cost: 130.074834\t Valid Acc: 0.2402999997138977.\n",
            "Epoch: 2 \tTraining Cost: 126.449328\t Valid Acc: 0.4551999866962433.\n",
            "Epoch: 3 \tTraining Cost: 119.921593\t Valid Acc: 0.3172999918460846.\n",
            "Epoch: 4 \tTraining Cost: 119.272793\t Valid Acc: 0.439300000667572.\n",
            "Epoch: 5 \tTraining Cost: 110.628913\t Valid Acc: 0.1559000015258789.\n",
            "Epoch: 6 \tTraining Cost: 107.264309\t Valid Acc: 0.3506999909877777.\n",
            "Epoch: 7 \tTraining Cost: 108.479375\t Valid Acc: 0.4382999837398529.\n",
            "Epoch: 8 \tTraining Cost: 101.438738\t Valid Acc: 0.33219999074935913.\n",
            "Epoch: 9 \tTraining Cost: 100.466031\t Valid Acc: 0.30059999227523804.\n",
            "Epoch: 10 \tTraining Cost: 95.636315\t Valid Acc: 0.47759997844696045.\n",
            "Epoch: 11 \tTraining Cost: 94.670391\t Valid Acc: 0.5309999585151672.\n",
            "Epoch: 12 \tTraining Cost: 95.813981\t Valid Acc: 0.44259998202323914.\n",
            "Epoch: 13 \tTraining Cost: 91.725396\t Valid Acc: 0.48569998145103455.\n",
            "Epoch: 14 \tTraining Cost: 87.265924\t Valid Acc: 0.44449999928474426.\n",
            "Epoch: 15 \tTraining Cost: 82.336355\t Valid Acc: 0.1947999894618988.\n",
            "Epoch: 16 \tTraining Cost: 81.662859\t Valid Acc: 0.28949999809265137.\n",
            "Epoch: 17 \tTraining Cost: 85.085079\t Valid Acc: 0.28630000352859497.\n",
            "Epoch: 18 \tTraining Cost: 77.568496\t Valid Acc: 0.5004000067710876.\n",
            "Epoch: 19 \tTraining Cost: 74.994949\t Valid Acc: 0.54339998960495.\n",
            "[2023-12-06 16:02:23] training end\n"
          ]
        }
      ],
      "source": [
        "acc_list_MNIST_Gaussian = condensed_images_and_evaluate(\"MNIST\", \"ConvNet\", \"ConvNet\", True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rCpEe0hFm8pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d4c806-2a20-4af7-ba8c-16500af58973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-06 16:18:10] training begins\n",
            "[2023-12-06 18:32:36] training begins\n",
            "Epoch: 0 \tTraining Cost: 7.842100\t Valid Acc: 0.6333333253860474.\n",
            "Epoch: 1 \tTraining Cost: 5.361252\t Valid Acc: 0.5317460298538208.\n",
            "Epoch: 2 \tTraining Cost: 2.949223\t Valid Acc: 0.5365079641342163.\n",
            "Epoch: 3 \tTraining Cost: 1.523403\t Valid Acc: 0.5523809790611267.\n",
            "Epoch: 4 \tTraining Cost: 0.940079\t Valid Acc: 0.5428571701049805.\n",
            "Epoch: 5 \tTraining Cost: 0.673972\t Valid Acc: 0.5285714268684387.\n",
            "Epoch: 6 \tTraining Cost: 0.523605\t Valid Acc: 0.5206349492073059.\n",
            "Epoch: 7 \tTraining Cost: 0.427342\t Valid Acc: 0.5047619342803955.\n",
            "Epoch: 8 \tTraining Cost: 0.361695\t Valid Acc: 0.5.\n",
            "Epoch: 9 \tTraining Cost: 0.310622\t Valid Acc: 0.4888888895511627.\n",
            "Epoch: 10 \tTraining Cost: 0.272902\t Valid Acc: 0.5.\n",
            "Epoch: 11 \tTraining Cost: 0.242280\t Valid Acc: 0.49365079402923584.\n",
            "Epoch: 12 \tTraining Cost: 0.216573\t Valid Acc: 0.5031746029853821.\n",
            "Epoch: 13 \tTraining Cost: 0.195417\t Valid Acc: 0.49365079402923584.\n",
            "Epoch: 14 \tTraining Cost: 0.178241\t Valid Acc: 0.49365079402923584.\n",
            "Epoch: 15 \tTraining Cost: 0.164018\t Valid Acc: 0.5.\n",
            "Epoch: 16 \tTraining Cost: 0.151726\t Valid Acc: 0.49841269850730896.\n",
            "Epoch: 17 \tTraining Cost: 0.141044\t Valid Acc: 0.49841269850730896.\n",
            "Epoch: 18 \tTraining Cost: 0.132101\t Valid Acc: 0.4968253970146179.\n",
            "Epoch: 19 \tTraining Cost: 0.123874\t Valid Acc: 0.5.\n",
            "[2023-12-06 18:35:51] training end\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 128\n",
        "acc_list_MHIST_Gaussian = condensed_images_and_evaluate_MHIST(\"MHIST\", \"ConvNet7\", \"ConvNet7\", True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Cross-architecture Generalization."
      ],
      "metadata": {
        "id": "Tw7bfOnYCvh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condensed_images_and_evaluate(\"MNIST\", \"ConvNet\", \"AlexNet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFg6FyPYVS_4",
        "outputId": "7e1194b4-1fe7-41b7-f4a1-29fef0a5efc5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-06 22:53:15] training begins\n",
            "[2023-12-07 00:31:52] training begins\n",
            "Epoch: 0 \tTraining Cost: 115.587542\t Valid Acc: 0.11659999936819077.\n",
            "Epoch: 1 \tTraining Cost: 113.451244\t Valid Acc: 0.0982000008225441.\n",
            "Epoch: 2 \tTraining Cost: 111.990371\t Valid Acc: 0.10819999873638153.\n",
            "Epoch: 3 \tTraining Cost: 109.741653\t Valid Acc: 0.18140000104904175.\n",
            "Epoch: 4 \tTraining Cost: 106.350724\t Valid Acc: 0.10089999437332153.\n",
            "Epoch: 5 \tTraining Cost: 103.251298\t Valid Acc: 0.621999979019165.\n",
            "Epoch: 6 \tTraining Cost: 96.646477\t Valid Acc: 0.5633000135421753.\n",
            "Epoch: 7 \tTraining Cost: 91.891493\t Valid Acc: 0.44119998812675476.\n",
            "Epoch: 8 \tTraining Cost: 88.682129\t Valid Acc: 0.6237999796867371.\n",
            "Epoch: 9 \tTraining Cost: 84.548551\t Valid Acc: 0.5566999912261963.\n",
            "Epoch: 10 \tTraining Cost: 78.374485\t Valid Acc: 0.5960999727249146.\n",
            "Epoch: 11 \tTraining Cost: 75.461601\t Valid Acc: 0.5995999574661255.\n",
            "Epoch: 12 \tTraining Cost: 74.107934\t Valid Acc: 0.5949999690055847.\n",
            "Epoch: 13 \tTraining Cost: 71.147687\t Valid Acc: 0.5949999690055847.\n",
            "Epoch: 14 \tTraining Cost: 69.685937\t Valid Acc: 0.5773999691009521.\n",
            "Epoch: 15 \tTraining Cost: 64.119941\t Valid Acc: 0.46699997782707214.\n",
            "Epoch: 16 \tTraining Cost: 66.127680\t Valid Acc: 0.5126000046730042.\n",
            "Epoch: 17 \tTraining Cost: 62.309082\t Valid Acc: 0.5740999579429626.\n",
            "Epoch: 18 \tTraining Cost: 63.822690\t Valid Acc: 0.632099986076355.\n",
            "Epoch: 19 \tTraining Cost: 56.462703\t Valid Acc: 0.6015999913215637.\n",
            "[2023-12-07 00:34:25] training end\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.1166, device='cuda:0'),\n",
              " tensor(0.0982, device='cuda:0'),\n",
              " tensor(0.1082, device='cuda:0'),\n",
              " tensor(0.1814, device='cuda:0'),\n",
              " tensor(0.1009, device='cuda:0'),\n",
              " tensor(0.6220, device='cuda:0'),\n",
              " tensor(0.5633, device='cuda:0'),\n",
              " tensor(0.4412, device='cuda:0'),\n",
              " tensor(0.6238, device='cuda:0'),\n",
              " tensor(0.5567, device='cuda:0'),\n",
              " tensor(0.5961, device='cuda:0'),\n",
              " tensor(0.5996, device='cuda:0'),\n",
              " tensor(0.5950, device='cuda:0'),\n",
              " tensor(0.5950, device='cuda:0'),\n",
              " tensor(0.5774, device='cuda:0'),\n",
              " tensor(0.4670, device='cuda:0'),\n",
              " tensor(0.5126, device='cuda:0'),\n",
              " tensor(0.5741, device='cuda:0'),\n",
              " tensor(0.6321, device='cuda:0'),\n",
              " tensor(0.6016, device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "condensed_images_and_evaluate(\"MNIST\", \"ConvNet\", \"VGG11\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIElnanVBohC",
        "outputId": "86510d49-2ce0-46c2-88b8-a35c7e8f5e0b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-06 18:36:14] training begins\n",
            "[2023-12-06 20:13:48] training begins\n",
            "Epoch: 0 \tTraining Cost: 268.037476\t Valid Acc: 0.0973999947309494.\n",
            "Epoch: 1 \tTraining Cost: 161.781989\t Valid Acc: 0.0973999947309494.\n",
            "Epoch: 2 \tTraining Cost: 144.536239\t Valid Acc: 0.0957999974489212.\n",
            "Epoch: 3 \tTraining Cost: 146.139456\t Valid Acc: 0.0957999974489212.\n",
            "Epoch: 4 \tTraining Cost: 138.595403\t Valid Acc: 0.09799999743700027.\n",
            "Epoch: 5 \tTraining Cost: 131.886279\t Valid Acc: 0.17489999532699585.\n",
            "Epoch: 6 \tTraining Cost: 129.902572\t Valid Acc: 0.33149999380111694.\n",
            "Epoch: 7 \tTraining Cost: 117.027888\t Valid Acc: 0.28189998865127563.\n",
            "Epoch: 8 \tTraining Cost: 113.296620\t Valid Acc: 0.26829999685287476.\n",
            "Epoch: 9 \tTraining Cost: 113.713710\t Valid Acc: 0.16599999368190765.\n",
            "Epoch: 10 \tTraining Cost: 106.555901\t Valid Acc: 0.3779999911785126.\n",
            "Epoch: 11 \tTraining Cost: 102.909308\t Valid Acc: 0.28290000557899475.\n",
            "Epoch: 12 \tTraining Cost: 102.609542\t Valid Acc: 0.4041000008583069.\n",
            "Epoch: 13 \tTraining Cost: 97.317133\t Valid Acc: 0.39389997720718384.\n",
            "Epoch: 14 \tTraining Cost: 91.723286\t Valid Acc: 0.44099998474121094.\n",
            "Epoch: 15 \tTraining Cost: 82.431891\t Valid Acc: 0.4624999761581421.\n",
            "Epoch: 16 \tTraining Cost: 79.186654\t Valid Acc: 0.36890000104904175.\n",
            "Epoch: 17 \tTraining Cost: 77.926636\t Valid Acc: 0.4715999960899353.\n",
            "Epoch: 18 \tTraining Cost: 71.657040\t Valid Acc: 0.4795999825000763.\n",
            "Epoch: 19 \tTraining Cost: 72.213412\t Valid Acc: 0.4530999958515167.\n",
            "[2023-12-06 20:18:25] training end\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.0974, device='cuda:0'),\n",
              " tensor(0.0974, device='cuda:0'),\n",
              " tensor(0.0958, device='cuda:0'),\n",
              " tensor(0.0958, device='cuda:0'),\n",
              " tensor(0.0980, device='cuda:0'),\n",
              " tensor(0.1749, device='cuda:0'),\n",
              " tensor(0.3315, device='cuda:0'),\n",
              " tensor(0.2819, device='cuda:0'),\n",
              " tensor(0.2683, device='cuda:0'),\n",
              " tensor(0.1660, device='cuda:0'),\n",
              " tensor(0.3780, device='cuda:0'),\n",
              " tensor(0.2829, device='cuda:0'),\n",
              " tensor(0.4041, device='cuda:0'),\n",
              " tensor(0.3939, device='cuda:0'),\n",
              " tensor(0.4410, device='cuda:0'),\n",
              " tensor(0.4625, device='cuda:0'),\n",
              " tensor(0.3689, device='cuda:0'),\n",
              " tensor(0.4716, device='cuda:0'),\n",
              " tensor(0.4796, device='cuda:0'),\n",
              " tensor(0.4531, device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def condensed_images_and_evaluate_MHIST_2(dataset_name, model_name, eval_mode_name, randmon_init=False):\n",
        "  channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(\"MNIST\", \"/content/drive/MyDrive/MNIST\")\n",
        "  channel = 3\n",
        "  num_classes = 2\n",
        "  dst_train = train_set\n",
        "  dst_test = test_set\n",
        "  im_size = (224,224)\n",
        "\n",
        "  class_index = {}\n",
        "  data_save = []\n",
        "  for i in range(len(dst_train)):\n",
        "    lable = dst_train[i][1]\n",
        "    if lable in class_index:\n",
        "      class_index[lable].append(i)\n",
        "    else:\n",
        "      class_index[lable] = [i]\n",
        "  images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
        "  images_all = torch.cat(images_all, dim=0).to(DEVICE)\n",
        "  syn_image = []\n",
        "  for c in range(num_classes):\n",
        "    idx_shuffle = np.random.permutation(class_index[c])[:IMAGE_PER_CLASS]\n",
        "    syn_image.append(images_all[idx_shuffle])\n",
        "  syn_image = torch.cat(syn_image, dim=0).to(DEVICE)\n",
        "  syn_image.requires_grad = True\n",
        "  syn_lable = []\n",
        "  for c in range(num_classes):\n",
        "    syn_lable += [c for i in range(IMAGE_PER_CLASS)]\n",
        "  if randmon_init:\n",
        "    syn_image = torch.randn(size=(num_classes*IMAGE_PER_CLASS, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=DEVICE)\n",
        "  syn_lable = torch.tensor(syn_lable,device=DEVICE)\n",
        "  optimizer_img = torch.optim.SGD([syn_image, ], lr=LR_IMG)\n",
        "  criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "  total_loss = 0\n",
        "  print('%s training begins'%get_time())\n",
        "  for exp in range(NUMBER_INITIALIZATIONS):\n",
        "    #model = get_network(model_name, channel, num_classes, im_size).to(DEVICE)\n",
        "    model = ConvNet7(channel=3, num_classes=2, net_width=net_width, net_depth=7, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=(224,224)).to(DEVICE)\n",
        "    model.train()\n",
        "    net_parameters = list(model.parameters())\n",
        "\n",
        "    for it in range(ITERATIONS):\n",
        "      loss = torch.tensor(0.0).to(DEVICE)\n",
        "      for c in range(num_classes):\n",
        "        strat_index = c*IMAGE_PER_CLASS\n",
        "        img_real = images_all[np.random.permutation(class_index[c])[:BATCH_SIZE]]\n",
        "        lab_real = torch.ones((BATCH_SIZE,), device=DEVICE, dtype=torch.long) * c\n",
        "        img_syn = syn_image[strat_index: strat_index + IMAGE_PER_CLASS].reshape((IMAGE_PER_CLASS, channel, im_size[0], im_size[1]))\n",
        "        lab_syn = torch.ones((IMAGE_PER_CLASS,), device=DEVICE, dtype=torch.long) * c\n",
        "        output_real = model(img_real)\n",
        "        loss_real = criterion(output_real, lab_real)\n",
        "        gw_real = torch.autograd.grad(loss_real, net_parameters)\n",
        "        gw_real = list((_.detach().clone() for _ in gw_real))\n",
        "\n",
        "        output_syn = model(img_syn)\n",
        "        loss_syn = criterion(output_syn, lab_syn)\n",
        "        gw_syn = torch.autograd.grad(loss_syn, net_parameters, create_graph=True)\n",
        "        loss += match_mse_loss(gw_syn, gw_real)\n",
        "\n",
        "      total_loss += loss\n",
        "      optimizer_img.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer_img.step()\n",
        "\n",
        "      image_syn_train, label_syn_train = copy.deepcopy(syn_image.detach()), copy.deepcopy(syn_lable.detach())  # avoid any unaware modification\n",
        "      train_model(model, image_syn_train, label_syn_train, NUMBER_STEP_OPT)\n",
        "\n",
        "  random = \"Gaussian noise\" if randmon_init else \"real training images\"\n",
        "  save_name = os.path.join(SAVEPATH, 'vis_%s_%s_%s_%d.png'%(model_name, dataset_name, random, IMAGE_PER_CLASS))\n",
        "  image_syn_vis = copy.deepcopy(syn_image.detach().cpu())\n",
        "  save_image(image_syn_vis, save_name, nrow=IMAGE_PER_CLASS)\n",
        "  make_grid(image_syn_vis, nrow=IMAGE_PER_CLASS)\n",
        "  net_eval = get_network(eval_mode_name, channel, num_classes, im_size).to(DEVICE)\n",
        "  #net_eval = ConvNet7(channel=3, num_classes=2, net_width=net_width, net_depth=7, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=(224,224)).to(DEVICE)\n",
        "  image_syn_eval = copy.deepcopy(syn_image.detach())\n",
        "\n",
        "  print('%s training begins'%get_time())\n",
        "  acc_test = train_and_eval(net_eval, image_syn_eval, syn_lable, dst_test)\n",
        "  print('%s training end'%get_time())\n",
        "  return acc_test"
      ],
      "metadata": {
        "id": "pgUVgfO0tNEm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list_MHIST_cross = condensed_images_and_evaluate_MHIST_2(\"MHIST\", \"ConvNet\", \"VGG11\")"
      ],
      "metadata": {
        "id": "0Feos1PUtUW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list_MHIST_cross = condensed_images_and_evaluate_MHIST_2(\"MHIST\", \"ConvNet7\", \"AlexNet\")"
      ],
      "metadata": {
        "id": "Z9gPn73y0Oyj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "3ey80VXUC_8R",
        "c7SIb8fIf3ZA",
        "3b1g6jtwoA-1",
        "e9_97KLpinaR",
        "Cba9OLoziORR",
        "FCpDrDagdk7W",
        "Tw7bfOnYCvh8"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}